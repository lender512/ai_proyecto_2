{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia Artificial Proyecto #2: Clasificación\n",
    "## Integrantes\n",
    "    - Luis Berrospi\n",
    "    - Pedro Dominguez\n",
    "    - Carlos Esteban Guerrero Robles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Librerías que permitirá reducir dimensiones\n",
    "import pywt\n",
    "import pywt.data\n",
    "\n",
    "#Librerías para lectura/edición de imágenes\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "#Librerías para generar gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "#Librerías de modelos de clasificación\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold # k fold cross validation\n",
    "from sklearn import metrics # k fold cross validation\n",
    "from sklearn.metrics import recall_score, average_precision_score, roc_auc_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"../data/sign_mnist_train.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "df_train_x = df_train.loc[:, \"pixel1\":\"pixel784\"]\n",
    "df_train_y = df_train.label\n",
    "\n",
    "df_train = df_train.to_numpy()\n",
    "\n",
    "test_csv_path = \"../data/sign_mnist_test.csv\"\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "df_test_x = df_test.loc[:, \"pixel1\":\"pixel784\"]\n",
    "df_test_y = df_test.label\n",
    "\n",
    "df_test = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimension(letter, cuts, wavelet):\n",
    "  for i in range(cuts):\n",
    "    (letter, cD) = pywt.dwt(letter, wavelet)\n",
    "  return letter\n",
    "\n",
    "def vectorizar(matrix):\n",
    "  return matrix.flatten()\n",
    "\n",
    "def proccess_letters(dataset, wavelet, cuts = 2):\n",
    "  \n",
    "  data_X = []\n",
    "  data_Y = []\n",
    "\n",
    "  for letter_features in dataset:\n",
    "      \n",
    "      letter = letter_features[0]\n",
    "      data_Y.append(letter)\n",
    "\n",
    "      letter_features = reduce_dimension(letter_features[1:], cuts, wavelet)\n",
    "      letter_features = vectorizar(letter_features)\n",
    "      data_X.append(letter_features)\n",
    "\n",
    "  return data_X, data_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_family_wavelets = ['haar', 'bior', 'coif', 'rbio', 'sym', 'db', 'dmey']\n",
    "discrete_wavelets = {family:pywt.wavelist(family) for family in discrete_family_wavelets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_cuts = range(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors_list = [3, 6, 12, 24, 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_train.shape)\n",
    "#print(df_test.shape)\n",
    "random_state = 0\n",
    "pca = make_pipeline(StandardScaler(), PCA(n_components=2, random_state=random_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_experiment(classification, get_accuracy):\n",
    "    experiment_wavelets = dict()\n",
    "\n",
    "    for family, wavelets in discrete_wavelets.items():\n",
    "        wavelets_accuracy_list = list()\n",
    "        \n",
    "        for wavelet in wavelets:\n",
    "            df_train_x, df_train_y = proccess_letters(df_train, wavelet)\n",
    "            df_test_x, df_test_y = proccess_letters(df_test, wavelet)\n",
    "\n",
    "            prediction = classification(df_train_x, df_train_y, df_test_x)\n",
    "            accuracy = get_accuracy(prediction)\n",
    "\n",
    "            wavelets_accuracy_list.append((wavelet, accuracy))\n",
    "        \n",
    "        experiment_wavelets[family] = wavelets_accuracy_list\n",
    "    \n",
    "    return experiment_wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_experiment(classification, get_accuracy, wavelet):\n",
    "    experiment_dimensions = dict()\n",
    "\n",
    "    print(\"Cuts Dimensions Accuracy\")\n",
    "    \n",
    "    for cut in dimension_cuts:\n",
    "\n",
    "        df_train_x, df_train_y = proccess_letters(df_train, wavelet, cuts=cut)\n",
    "        df_test_x, df_test_y = proccess_letters(df_test, wavelet, cuts=cut)\n",
    "\n",
    "        prediction = classification(df_train_x, df_train_y, df_test_x)\n",
    "        accuracy = get_accuracy(prediction)\n",
    "\n",
    "        dimensions = len(df_train_x[0])\n",
    "        \n",
    "        print(f'{cut}   {dimensions}       {accuracy}')\n",
    "        experiment_dimensions[cut] = [(dimensions, accuracy)]\n",
    "    \n",
    "    return experiment_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel experiment (Only SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_experiment(classification, get_accuracy, wavelet):\n",
    "    experiment_dimensions = dict()\n",
    "\n",
    "    print(\"Kernel Accuracy\")\n",
    "    \n",
    "    for kernel in kernels:\n",
    "\n",
    "        df_train_x, df_train_y = proccess_letters(df_train, wavelet)\n",
    "        df_test_x, df_test_y = proccess_letters(df_test, wavelet)\n",
    "\n",
    "        prediction = classification(df_train_x, df_train_y, df_test_x, kernel)\n",
    "        accuracy = get_accuracy(prediction)\n",
    "        \n",
    "        print(f'{kernel} {accuracy}')\n",
    "        experiment_dimensions[kernel] = [(kernel, accuracy)]\n",
    "    \n",
    "    return experiment_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-neighbors experiment (Only KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors_experiment(classification, get_accuracy, wavelet):\n",
    "    experiment_dimensions = dict()\n",
    "\n",
    "    print(\"Neighbors Accuracy\")\n",
    "    \n",
    "    for k in k_neighbors_list:\n",
    "\n",
    "        df_train_x, df_train_y = proccess_letters(df_train, wavelet)\n",
    "        df_test_x, df_test_y = proccess_letters(df_test, wavelet)\n",
    "\n",
    "        prediction = classification(df_train_x, df_train_y, df_test_x, k)\n",
    "        accuracy = get_accuracy(prediction)\n",
    "        \n",
    "        print(f'{k} {accuracy}')\n",
    "        experiment_dimensions[k] = [(k, accuracy)]\n",
    "    \n",
    "    return experiment_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_results(experiment):\n",
    "    max_results = list()\n",
    "    parameters = list()\n",
    "\n",
    "    for parameter, result in experiment.items():\n",
    "        index = len(result[0]) - 1\n",
    "\n",
    "        max_result = max(result, key = lambda tuple: tuple[index])\n",
    "        max_results.append(max_result)\n",
    "\n",
    "        parameters.append(parameter)\n",
    "\n",
    "    return parameters, max_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df_train, df_test, wavelet, classification, get_precision):\n",
    "\n",
    "    df_train_x, df_train_y = proccess_letters(df_train, wavelet)\n",
    "    df_test_x, df_test_y = proccess_letters(df_test, wavelet)\n",
    "\n",
    "    y_pred = classification(df_train_x, df_train_y, df_test_x)\n",
    "    \n",
    "    homemade_precision_y = get_precision(y_pred)\n",
    "\n",
    "    precision_y = precision_score(df_test_y, y_pred, average='macro')\n",
    "    recall_y = recall_score(df_test_y, y_pred, average='micro')\n",
    "    f1_y = f1_score(df_test_y, y_pred, average='micro')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(df_test_y, y_pred, pos_label = 24)\n",
    "    auc_y = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print(\"SKlearn precision: \", precision_y)\n",
    "    print(\"Homemade precision: \", homemade_precision_y / 100)\n",
    "    print(\"SKlearn recall: \", recall_y)\n",
    "    print(\"SKlearn F1: \", f1_y)\n",
    "    print(\"SKlearn AUC: \", auc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification(df_train_x, df_train_y, df_test_x, k = 24):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(df_train_x,df_train_y)\n",
    "    knn_predicted = knn.predict(df_test_x)\n",
    "\n",
    "    return knn_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KNN_error(knn_predicted):\n",
    "    knn_success = 0.0\n",
    "    \n",
    "    for i, val in enumerate(knn_predicted):\n",
    "        if val == df_test_y[i]:\n",
    "            knn_success += 1\n",
    "\n",
    "    return knn_success/len(knn_predicted)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "knn_experiment_wavelets = wavelet_experiment(KNN_classification, get_KNN_error)\n",
    "\n",
    "knn_family_wavelet_parameters, knn_family_wavelet_max_results = get_max_results(knn_experiment_wavelets)\n",
    "\n",
    "print(\"KNN wavelets experiment:\")\n",
    "print(list(zip(knn_family_wavelet_parameters, knn_family_wavelet_max_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = '' #Usa el wavelet con mayor porcentaje de prediccción\n",
    "\n",
    "knn_experiment_dimension = dimension_experiment(KNN_classification, get_KNN_error, w)\n",
    "\n",
    "knn_cut_parameters, knn_cut_max_results = get_max_results(knn_experiment_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_experiment_neighbors = k_neighbors_experiment(KNN_classification, get_KNN_error, w)\n",
    "\n",
    "knn_neighbors_parameters, knn_neighbors_max_results = get_max_results(knn_experiment_neighbors)\n",
    "\n",
    "#print(\"SVM wavelets experiment:\")\n",
    "#svm_wavelets_parameters, svm_wavelets_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(df_train, df_test, \"db4\", KNN_classification, get_KNN_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_classification(df_train_x, df_train_y, df_test_x, kernel_type = 'rbf'):\n",
    "    _svm = svm.SVC(kernel=kernel_type)\n",
    "    _svm.fit(df_train_x,df_train_y)\n",
    "    svm_predicted = _svm.predict(df_test_x)\n",
    "\n",
    "    return svm_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SVM_error(svm_predicted):\n",
    "    svm_success = 0.0\n",
    "    for i, val in enumerate(svm_predicted):\n",
    "        if val == df_test_y[i]:\n",
    "            svm_success += 1\n",
    "            \n",
    "    return svm_success/len(svm_predicted)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('haar', 80.77244841048523)\n",
      "('bior1.5', 82.40379252649191)\n",
      "('coif5', 83.58895705521472)\n",
      "('rbio2.2', 83.4495259341885)\n",
      "('sym5', 83.5750139431121)\n",
      "('db4', 83.61684327941997)\n",
      "('dmey', 81.51143335192414)\n"
     ]
    }
   ],
   "source": [
    "svm_experiment_wavelets = wavelet_experiment(SVM_classification, get_SVM_error)\n",
    "\n",
    "svm_wavelets_parameters, svm_wavelets_max_results = get_max_results(svm_experiment_wavelets)\n",
    "\n",
    "print(\"SVM wavelets experiment:\")\n",
    "svm_wavelets_parameters, svm_wavelets_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Accuracy\n",
      "linear 83.61684327941997\n",
      "poly 83.74233128834356\n",
      "rbf 87.00501952035694\n"
     ]
    }
   ],
   "source": [
    "svm_experiment_kernels = kernel_experiment(SVM_classification, get_SVM_error, 'db4')\n",
    "\n",
    "svm_kernel_parameters, svm_kernel_max_results = get_max_results(svm_experiment_kernels)\n",
    "\n",
    "#print(\"SVM wavelets experiment:\")\n",
    "#svm_wavelets_parameters, svm_wavelets_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuts Dimensions Accuracy\n",
      "0   784       78.16508644729504\n",
      "1   395       79.81037367540435\n",
      "2   201       83.61684327941997\n",
      "3   104       81.42777467930841\n",
      "4   55       71.91857222532069\n",
      "5   31       48.22922476296709\n"
     ]
    }
   ],
   "source": [
    "svm_experiment_dimensions = dimension_experiment(SVM_classification, get_SVM_error, 'db4')\n",
    "\n",
    "svm_cut_parameters, svm_cut_max_results = get_max_results(svm_experiment_dimensions)\n",
    "\n",
    "#print(\"SVM wavelets experiment:\")\n",
    "#svm_cut_parameters, svm_cut_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKlearn precision:  0.8361684327941996\n",
      "Homemade precision:  0.8361684327941997\n",
      "SKlearn recall:  0.8361684327941996\n",
      "SKlearn F1:  0.8361684327941996\n",
      "SKlearn AUC:  0.9303532110899739\n"
     ]
    }
   ],
   "source": [
    "get_metrics(df_train, df_test, \"db4\", SVM_classification, get_SVM_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_classification(df_train_x, df_train_y, df_test_x, split_criteria = 'gini'):\n",
    "    dt = tree.DecisionTreeClassifier(criterion=split_criteria)\n",
    "    dt.fit(df_train_x,df_train_y)\n",
    "    dt_predicted = dt.predict(df_test_x)\n",
    "\n",
    "    return dt_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DT_error(dt_predicted):\n",
    "    dt_success = 0.0\n",
    "    for i, val in enumerate(dt_predicted):\n",
    "        if val == df_test_y[i]:\n",
    "            dt_success += 1\n",
    "    return dt_success/len(dt_predicted)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tabla de resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('haar', 45.133853876185164)\n",
      "('bior1.3', 51.436140546569995)\n",
      "('coif5', 50.76687116564417)\n",
      "('rbio3.7', 53.471834913552705)\n",
      "('sym11', 52.900167317345236)\n",
      "('db31', 52.370329057445616)\n",
      "('dmey', 49.28890128276631)\n"
     ]
    }
   ],
   "source": [
    "dt_experiment_wavelets = wavelet_experiment(DT_classification, get_DT_error)\n",
    "\n",
    "dt_family_wavelet_parameters, dt_family_wavelet_max_results = get_max_results(dt_experiment_wavelets)\n",
    "\n",
    "print(\"Decision tree wavelets experiment:\")\n",
    "dt_family_wavelet_parameters, dt_family_wavelet_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuts Dimensions Accuracy\n",
      "0   784       43.363078639152256\n",
      "1   399       49.58170663692136\n",
      "2   207       52.593418851087556\n",
      "3   111       50.13943112102621\n",
      "4   63       43.01450083658673\n",
      "5   39       42.72169548243168\n"
     ]
    }
   ],
   "source": [
    "dt_experiment_dimension = dimension_experiment(DT_classification, get_DT_error, 'rbio3.7')\n",
    "\n",
    "dt_cut_parameters, dt_cut_max_results = get_max_results(dt_experiment_dimension)\n",
    "\n",
    "#print(\"Decision tree cuts/reduction experiment:\")\n",
    "#dt_cut_parameters, dt_cut_max_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKlearn precision:  0.5288622420524262\n",
      "Homemade precision:  0.5288622420524262\n",
      "SKlearn recall:  0.5288622420524262\n",
      "SKlearn F1:  0.5288622420524262\n",
      "SKlearn AUC:  0.776684809413091\n"
     ]
    }
   ],
   "source": [
    "get_metrics(df_train, df_test, \"rbio3.7\", DT_classification, get_DT_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_k_fold_cross_validation (model, x_train, y_train):\n",
    "    scores = cross_val_score(model, x_train, y_train)\n",
    "    errors = 1 - scores\n",
    "    return scores, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = svm.SVC(kernel = \"rbf\")\n",
    "\n",
    "#test_score, sklearn_k_fold_cross_validation(test_model, df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998183752613209\n",
      "0.9985594181958316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_model = svm.SVC(kernel = \"rbf\", probability = True)\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "df_train_x_t, df_train_y_t = proccess_letters(df_train, wavelet=\"db4\")\n",
    "df_test_x_t, df_test_y_t = proccess_letters(df_test, wavelet=\"db4\")\n",
    "\n",
    "\n",
    "df_training_x = np.array(df_train_x_t + df_test_x_t)\n",
    "df_training_y = np.array(df_train_y_t + df_test_y_t)\n",
    "\n",
    "for train_index, test_index in kf.split(df_training_x):\n",
    "    X_train, X_test = df_training_x[train_index], df_training_x[test_index]\n",
    "    y_train, y_test = df_training_y[train_index], df_training_y[test_index]\n",
    "    \n",
    "    test_model = test_model.fit(X_train, y_train)\n",
    "    roc_test = roc_auc_score(y_test, test_model.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "    print(roc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "67bb906f09da34e2c26e67dc6a9d867a380e7b8dec1e6d3996f99a1aad7ac05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
